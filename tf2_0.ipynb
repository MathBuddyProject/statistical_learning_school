{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST via TF's low-level Python API, 3 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "n_hidden1 = 200\n",
    "n_hidden2 = 200\n",
    "n_hidden3 = 100\n",
    "n_hidden4 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = tf.placeholder_with_default(False, shape=(), name='training') #Boolean switch which says if we're training or not\n",
    "\n",
    "dropout_rate = 0.25 #Hyperparameter: We drop 25% of the neurons at each step\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer(mode = \"FAN_AVG\")\n",
    "#We don't need this if we have SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the scaled exponential linear units look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Already available as a command in tf 1.4\n",
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropouts after every layer\n",
    "with tf.name_scope(\"layers\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, name=\"hidden1\", activation=selu, kernel_initializer=he_init)\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training) \n",
    "    #Dropout is implemented if training is true (training is false when we're classifying)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, name=\"hidden2\", activation=selu, kernel_initializer=he_init)\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    hidden3 = tf.layers.dense(hidden2_drop, n_hidden3, name=\"hidden3\", activation=selu,kernel_initializer=he_init)\n",
    "    hidden3_drop = tf.layers.dropout(hidden3, dropout_rate, training=training)\n",
    "    hidden4 = tf.layers.dense(hidden3_drop, n_hidden3, name=\"hidden4\", activation=selu,kernel_initializer=he_init)\n",
    "    hidden4_drop = tf.layers.dropout(hidden4, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden4_drop, n_outputs, name=\"outputs\") #We don't drop neurons from the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = tf.placeholder(tf.float32, shape=(), name=\"lr\")\n",
    "#Learning rate is a placeholder, because the optimizer will select its own\n",
    "\n",
    "with tf.name_scope(\"minimize\"):\n",
    "    optimizer = tf.train.AdamOptimizer() #Forget Gradient Descent, we're using this thing\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "batch_size = 80\n",
    "final_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 \tTrain accuracy 0.6625 \tTest accuracy 0.9499\n",
      "Epoch  1 \tTrain accuracy 0.6000 \tTest accuracy 0.9642\n",
      "Epoch  2 \tTrain accuracy 0.7125 \tTest accuracy 0.9682\n",
      "Epoch  3 \tTrain accuracy 0.7375 \tTest accuracy 0.9651\n",
      "Epoch  4 \tTrain accuracy 0.8250 \tTest accuracy 0.9704\n",
      "Epoch  5 \tTrain accuracy 0.8375 \tTest accuracy 0.9700\n",
      "Epoch  6 \tTrain accuracy 0.8375 \tTest accuracy 0.9653\n",
      "Epoch  7 \tTrain accuracy 0.7000 \tTest accuracy 0.9712\n",
      "Epoch  8 \tTrain accuracy 0.7875 \tTest accuracy 0.9741\n",
      "Epoch  9 \tTrain accuracy 0.8625 \tTest accuracy 0.9743\n",
      "Epoch 10 \tTrain accuracy 0.7750 \tTest accuracy 0.9746\n",
      "Epoch 11 \tTrain accuracy 0.7750 \tTest accuracy 0.9725\n",
      "Epoch 12 \tTrain accuracy 0.7875 \tTest accuracy 0.9697\n",
      "Epoch 13 \tTrain accuracy 0.8625 \tTest accuracy 0.9730\n",
      "Epoch 14 \tTrain accuracy 0.6875 \tTest accuracy 0.9758\n",
      "Epoch 15 \tTrain accuracy 0.7625 \tTest accuracy 0.9696\n",
      "Epoch 16 \tTrain accuracy 0.7875 \tTest accuracy 0.9702\n",
      "Epoch 17 \tTrain accuracy 0.7875 \tTest accuracy 0.9709\n",
      "Epoch 18 \tTrain accuracy 0.8750 \tTest accuracy 0.9766\n",
      "Epoch 19 \tTrain accuracy 0.8375 \tTest accuracy 0.9783\n",
      "Epoch 20 \tTrain accuracy 0.8000 \tTest accuracy 0.9740\n",
      "Epoch 21 \tTrain accuracy 0.7875 \tTest accuracy 0.9731\n",
      "Epoch 22 \tTrain accuracy 0.7875 \tTest accuracy 0.9760\n",
      "Epoch 23 \tTrain accuracy 0.8375 \tTest accuracy 0.9775\n",
      "Epoch 24 \tTrain accuracy 0.8125 \tTest accuracy 0.9714\n",
      "Epoch 25 \tTrain accuracy 0.7750 \tTest accuracy 0.9786\n",
      "Epoch 26 \tTrain accuracy 0.8750 \tTest accuracy 0.9681\n",
      "Epoch 27 \tTrain accuracy 0.8625 \tTest accuracy 0.9757\n",
      "Epoch 28 \tTrain accuracy 0.7625 \tTest accuracy 0.9758\n",
      "Epoch 29 \tTrain accuracy 0.8500 \tTest accuracy 0.9763\n",
      "Epoch 30 \tTrain accuracy 0.8375 \tTest accuracy 0.9753\n",
      "Epoch 31 \tTrain accuracy 0.7750 \tTest accuracy 0.9752\n",
      "Epoch 32 \tTrain accuracy 0.8750 \tTest accuracy 0.9740\n",
      "Epoch 33 \tTrain accuracy 0.8000 \tTest accuracy 0.9765\n",
      "Epoch 34 \tTrain accuracy 0.7750 \tTest accuracy 0.9773\n",
      "Epoch 35 \tTrain accuracy 0.8250 \tTest accuracy 0.9772\n",
      "Epoch 36 \tTrain accuracy 0.7750 \tTest accuracy 0.9764\n",
      "Epoch 37 \tTrain accuracy 0.7625 \tTest accuracy 0.9769\n",
      "Epoch 38 \tTrain accuracy 0.8000 \tTest accuracy 0.9795\n",
      "Epoch 39 \tTrain accuracy 0.8750 \tTest accuracy 0.9758\n",
      "Epoch 40 \tTrain accuracy 0.8375 \tTest accuracy 0.9771\n",
      "Epoch 41 \tTrain accuracy 0.8000 \tTest accuracy 0.9788\n",
      "Epoch 42 \tTrain accuracy 0.8375 \tTest accuracy 0.9742\n",
      "Epoch 43 \tTrain accuracy 0.8000 \tTest accuracy 0.9761\n",
      "Epoch 44 \tTrain accuracy 0.8375 \tTest accuracy 0.9774\n",
      "Epoch 45 \tTrain accuracy 0.8875 \tTest accuracy 0.9713\n",
      "Epoch 46 \tTrain accuracy 0.8125 \tTest accuracy 0.9754\n",
      "Epoch 47 \tTrain accuracy 0.8000 \tTest accuracy 0.9747\n",
      "Epoch 48 \tTrain accuracy 0.8250 \tTest accuracy 0.9769\n",
      "Epoch 49 \tTrain accuracy 0.8375 \tTest accuracy 0.9776\n",
      "Epoch 50 \tTrain accuracy 0.8250 \tTest accuracy 0.9753\n",
      "Epoch 51 \tTrain accuracy 0.9125 \tTest accuracy 0.9761\n",
      "Epoch 52 \tTrain accuracy 0.7500 \tTest accuracy 0.9758\n",
      "Epoch 53 \tTrain accuracy 0.7875 \tTest accuracy 0.9750\n",
      "Epoch 54 \tTrain accuracy 0.8750 \tTest accuracy 0.9776\n",
      "Epoch 55 \tTrain accuracy 0.8500 \tTest accuracy 0.9749\n",
      "Epoch 56 \tTrain accuracy 0.8125 \tTest accuracy 0.9749\n",
      "Epoch 57 \tTrain accuracy 0.8000 \tTest accuracy 0.9778\n",
      "Epoch 58 \tTrain accuracy 0.8625 \tTest accuracy 0.9792\n",
      "Epoch 59 \tTrain accuracy 0.9000 \tTest accuracy 0.9752\n",
      "Epoch 60 \tTrain accuracy 0.8625 \tTest accuracy 0.9761\n",
      "Epoch 61 \tTrain accuracy 0.8000 \tTest accuracy 0.9770\n",
      "Epoch 62 \tTrain accuracy 0.7750 \tTest accuracy 0.9793\n",
      "Epoch 63 \tTrain accuracy 0.8375 \tTest accuracy 0.9753\n",
      "Epoch 64 \tTrain accuracy 0.9000 \tTest accuracy 0.9779\n",
      "Epoch 65 \tTrain accuracy 0.8125 \tTest accuracy 0.9800\n",
      "Epoch 66 \tTrain accuracy 0.8125 \tTest accuracy 0.9749\n",
      "Epoch 67 \tTrain accuracy 0.8625 \tTest accuracy 0.9756\n",
      "Epoch 68 \tTrain accuracy 0.8250 \tTest accuracy 0.9785\n",
      "Epoch 69 \tTrain accuracy 0.8375 \tTest accuracy 0.9782\n",
      "Epoch 70 \tTrain accuracy 0.8375 \tTest accuracy 0.9779\n",
      "Epoch 71 \tTrain accuracy 0.8750 \tTest accuracy 0.9783\n",
      "Epoch 72 \tTrain accuracy 0.8375 \tTest accuracy 0.9788\n",
      "Epoch 73 \tTrain accuracy 0.8000 \tTest accuracy 0.9722\n",
      "Epoch 74 \tTrain accuracy 0.8000 \tTest accuracy 0.9785\n",
      "Epoch 75 \tTrain accuracy 0.8875 \tTest accuracy 0.9770\n",
      "Epoch 76 \tTrain accuracy 0.8625 \tTest accuracy 0.9817\n",
      "Epoch 77 \tTrain accuracy 0.8500 \tTest accuracy 0.9805\n",
      "Epoch 78 \tTrain accuracy 0.8000 \tTest accuracy 0.9804\n",
      "Epoch 79 \tTrain accuracy 0.8125 \tTest accuracy 0.9784\n",
      "Epoch 80 \tTrain accuracy 0.8375 \tTest accuracy 0.9789\n",
      "Epoch 81 \tTrain accuracy 0.8625 \tTest accuracy 0.9772\n",
      "Epoch 82 \tTrain accuracy 0.8250 \tTest accuracy 0.9806\n",
      "Epoch 83 \tTrain accuracy 0.7750 \tTest accuracy 0.9769\n",
      "Epoch 84 \tTrain accuracy 0.8500 \tTest accuracy 0.9781\n",
      "Epoch 85 \tTrain accuracy 0.8375 \tTest accuracy 0.9779\n",
      "Epoch 86 \tTrain accuracy 0.8875 \tTest accuracy 0.9778\n",
      "Epoch 87 \tTrain accuracy 0.8375 \tTest accuracy 0.9794\n",
      "Epoch 88 \tTrain accuracy 0.8375 \tTest accuracy 0.9752\n",
      "Epoch 89 \tTrain accuracy 0.9000 \tTest accuracy 0.9802\n",
      "Epoch 90 \tTrain accuracy 0.8375 \tTest accuracy 0.9786\n",
      "Epoch 91 \tTrain accuracy 0.8250 \tTest accuracy 0.9766\n",
      "Epoch 92 \tTrain accuracy 0.8875 \tTest accuracy 0.9788\n",
      "Epoch 93 \tTrain accuracy 0.8000 \tTest accuracy 0.9810\n",
      "Epoch 94 \tTrain accuracy 0.8250 \tTest accuracy 0.9780\n",
      "Epoch 95 \tTrain accuracy 0.8625 \tTest accuracy 0.9781\n",
      "Epoch 96 \tTrain accuracy 0.8375 \tTest accuracy 0.9803\n",
      "Epoch 97 \tTrain accuracy 0.8625 \tTest accuracy 0.9784\n",
      "Epoch 98 \tTrain accuracy 0.8375 \tTest accuracy 0.9795\n",
      "Epoch 99 \tTrain accuracy 0.8875 \tTest accuracy 0.9795\n",
      "Epoch 100 \tTrain accuracy 0.8875 \tTest accuracy 0.9783\n",
      "Epoch 101 \tTrain accuracy 0.9375 \tTest accuracy 0.9793\n",
      "Epoch 102 \tTrain accuracy 0.9000 \tTest accuracy 0.9791\n",
      "Epoch 103 \tTrain accuracy 0.7625 \tTest accuracy 0.9796\n",
      "Epoch 104 \tTrain accuracy 0.8375 \tTest accuracy 0.9786\n",
      "Epoch 105 \tTrain accuracy 0.8875 \tTest accuracy 0.9804\n",
      "Epoch 106 \tTrain accuracy 0.8875 \tTest accuracy 0.9803\n",
      "Epoch 107 \tTrain accuracy 0.8750 \tTest accuracy 0.9789\n",
      "Epoch 108 \tTrain accuracy 0.8375 \tTest accuracy 0.9785\n",
      "Epoch 109 \tTrain accuracy 0.8375 \tTest accuracy 0.9804\n",
      "Epoch 110 \tTrain accuracy 0.8125 \tTest accuracy 0.9817\n",
      "Epoch 111 \tTrain accuracy 0.8125 \tTest accuracy 0.9796\n",
      "Epoch 112 \tTrain accuracy 0.9000 \tTest accuracy 0.9789\n",
      "Epoch 113 \tTrain accuracy 0.8500 \tTest accuracy 0.9803\n",
      "Epoch 114 \tTrain accuracy 0.8625 \tTest accuracy 0.9764\n",
      "Epoch 115 \tTrain accuracy 0.8125 \tTest accuracy 0.9816\n",
      "Epoch 116 \tTrain accuracy 0.7875 \tTest accuracy 0.9777\n",
      "Epoch 117 \tTrain accuracy 0.7750 \tTest accuracy 0.9800\n",
      "Epoch 118 \tTrain accuracy 0.8875 \tTest accuracy 0.9810\n",
      "Epoch 119 \tTrain accuracy 0.8250 \tTest accuracy 0.9796\n",
      "Epoch 120 \tTrain accuracy 0.8500 \tTest accuracy 0.9778\n",
      "Epoch 121 \tTrain accuracy 0.8125 \tTest accuracy 0.9765\n",
      "Epoch 122 \tTrain accuracy 0.9000 \tTest accuracy 0.9787\n",
      "Epoch 123 \tTrain accuracy 0.9000 \tTest accuracy 0.9796\n",
      "Epoch 124 \tTrain accuracy 0.8500 \tTest accuracy 0.9788\n",
      "Epoch 125 \tTrain accuracy 0.8125 \tTest accuracy 0.9798\n",
      "Epoch 126 \tTrain accuracy 0.8375 \tTest accuracy 0.9780\n",
      "Epoch 127 \tTrain accuracy 0.7375 \tTest accuracy 0.9793\n",
      "Epoch 128 \tTrain accuracy 0.8000 \tTest accuracy 0.9811\n",
      "Epoch 129 \tTrain accuracy 0.8000 \tTest accuracy 0.9780\n",
      "Epoch 130 \tTrain accuracy 0.8500 \tTest accuracy 0.9803\n",
      "Epoch 131 \tTrain accuracy 0.8250 \tTest accuracy 0.9799\n",
      "Epoch 132 \tTrain accuracy 0.8750 \tTest accuracy 0.9802\n",
      "Epoch 133 \tTrain accuracy 0.8125 \tTest accuracy 0.9775\n",
      "Epoch 134 \tTrain accuracy 0.8375 \tTest accuracy 0.9808\n",
      "Epoch 135 \tTrain accuracy 0.8250 \tTest accuracy 0.9806\n",
      "Epoch 136 \tTrain accuracy 0.8875 \tTest accuracy 0.9793\n",
      "Epoch 137 \tTrain accuracy 0.8250 \tTest accuracy 0.9797\n",
      "Epoch 138 \tTrain accuracy 0.8250 \tTest accuracy 0.9797\n",
      "Epoch 139 \tTrain accuracy 0.8625 \tTest accuracy 0.9787\n",
      "Epoch 140 \tTrain accuracy 0.8250 \tTest accuracy 0.9789\n",
      "Epoch 141 \tTrain accuracy 0.8375 \tTest accuracy 0.9798\n",
      "Epoch 142 \tTrain accuracy 0.8875 \tTest accuracy 0.9782\n",
      "Epoch 143 \tTrain accuracy 0.8000 \tTest accuracy 0.9771\n",
      "Epoch 144 \tTrain accuracy 0.8625 \tTest accuracy 0.9808\n",
      "Epoch 145 \tTrain accuracy 0.8500 \tTest accuracy 0.9787\n",
      "Epoch 146 \tTrain accuracy 0.8250 \tTest accuracy 0.9794\n",
      "Epoch 147 \tTrain accuracy 0.8625 \tTest accuracy 0.9819\n",
      "Epoch 148 \tTrain accuracy 0.7875 \tTest accuracy 0.9782\n",
      "Epoch 149 \tTrain accuracy 0.8250 \tTest accuracy 0.9797\n",
      "Epoch 150 \tTrain accuracy 0.7750 \tTest accuracy 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151 \tTrain accuracy 0.7250 \tTest accuracy 0.9791\n",
      "Epoch 152 \tTrain accuracy 0.8625 \tTest accuracy 0.9808\n",
      "Epoch 153 \tTrain accuracy 0.8500 \tTest accuracy 0.9783\n",
      "Epoch 154 \tTrain accuracy 0.8500 \tTest accuracy 0.9818\n",
      "Epoch 155 \tTrain accuracy 0.8000 \tTest accuracy 0.9805\n",
      "Epoch 156 \tTrain accuracy 0.8125 \tTest accuracy 0.9756\n",
      "Epoch 157 \tTrain accuracy 0.8500 \tTest accuracy 0.9792\n",
      "Epoch 158 \tTrain accuracy 0.8875 \tTest accuracy 0.9798\n",
      "Epoch 159 \tTrain accuracy 0.8125 \tTest accuracy 0.9800\n",
      "Epoch 160 \tTrain accuracy 0.8500 \tTest accuracy 0.9808\n",
      "Epoch 161 \tTrain accuracy 0.7875 \tTest accuracy 0.9833\n",
      "Epoch 162 \tTrain accuracy 0.9000 \tTest accuracy 0.9792\n",
      "Epoch 163 \tTrain accuracy 0.8250 \tTest accuracy 0.9787\n",
      "Epoch 164 \tTrain accuracy 0.8250 \tTest accuracy 0.9809\n",
      "Epoch 165 \tTrain accuracy 0.8750 \tTest accuracy 0.9810\n",
      "Epoch 166 \tTrain accuracy 0.8500 \tTest accuracy 0.9797\n",
      "Epoch 167 \tTrain accuracy 0.8250 \tTest accuracy 0.9799\n",
      "Epoch 168 \tTrain accuracy 0.8250 \tTest accuracy 0.9782\n",
      "Epoch 169 \tTrain accuracy 0.8000 \tTest accuracy 0.9813\n",
      "Epoch 170 \tTrain accuracy 0.8375 \tTest accuracy 0.9811\n",
      "Epoch 171 \tTrain accuracy 0.8500 \tTest accuracy 0.9802\n",
      "Epoch 172 \tTrain accuracy 0.8375 \tTest accuracy 0.9792\n",
      "Epoch 173 \tTrain accuracy 0.8625 \tTest accuracy 0.9795\n",
      "Epoch 174 \tTrain accuracy 0.8250 \tTest accuracy 0.9790\n",
      "Epoch 175 \tTrain accuracy 0.8250 \tTest accuracy 0.9793\n",
      "Epoch 176 \tTrain accuracy 0.8250 \tTest accuracy 0.9802\n",
      "Epoch 177 \tTrain accuracy 0.8375 \tTest accuracy 0.9801\n",
      "Epoch 178 \tTrain accuracy 0.8000 \tTest accuracy 0.9810\n",
      "Epoch 179 \tTrain accuracy 0.8250 \tTest accuracy 0.9773\n",
      "Epoch 180 \tTrain accuracy 0.8250 \tTest accuracy 0.9778\n",
      "Epoch 181 \tTrain accuracy 0.8750 \tTest accuracy 0.9799\n",
      "Epoch 182 \tTrain accuracy 0.8625 \tTest accuracy 0.9783\n",
      "Epoch 183 \tTrain accuracy 0.8375 \tTest accuracy 0.9791\n",
      "Epoch 184 \tTrain accuracy 0.7750 \tTest accuracy 0.9771\n",
      "Epoch 185 \tTrain accuracy 0.8625 \tTest accuracy 0.9757\n",
      "Epoch 186 \tTrain accuracy 0.8125 \tTest accuracy 0.9779\n",
      "Epoch 187 \tTrain accuracy 0.8000 \tTest accuracy 0.9782\n",
      "Epoch 188 \tTrain accuracy 0.7375 \tTest accuracy 0.9786\n",
      "Epoch 189 \tTrain accuracy 0.8500 \tTest accuracy 0.9795\n",
      "Epoch 190 \tTrain accuracy 0.7750 \tTest accuracy 0.9801\n",
      "Epoch 191 \tTrain accuracy 0.8500 \tTest accuracy 0.9793\n",
      "Epoch 192 \tTrain accuracy 0.8750 \tTest accuracy 0.9833\n",
      "Epoch 193 \tTrain accuracy 0.8250 \tTest accuracy 0.9825\n",
      "Epoch 194 \tTrain accuracy 0.8625 \tTest accuracy 0.9821\n",
      "Epoch 195 \tTrain accuracy 0.8375 \tTest accuracy 0.9807\n",
      "Epoch 196 \tTrain accuracy 0.8500 \tTest accuracy 0.9812\n",
      "Epoch 197 \tTrain accuracy 0.7875 \tTest accuracy 0.9803\n",
      "Epoch 198 \tTrain accuracy 0.7125 \tTest accuracy 0.9802\n",
      "Epoch 199 \tTrain accuracy 0.8000 \tTest accuracy 0.9798\n",
      "Epoch 200 \tTrain accuracy 0.8250 \tTest accuracy 0.9798\n",
      "Epoch 201 \tTrain accuracy 0.7875 \tTest accuracy 0.9750\n",
      "Epoch 202 \tTrain accuracy 0.8750 \tTest accuracy 0.9791\n",
      "Epoch 203 \tTrain accuracy 0.7750 \tTest accuracy 0.9787\n",
      "Epoch 204 \tTrain accuracy 0.8750 \tTest accuracy 0.9804\n",
      "Epoch 205 \tTrain accuracy 0.8250 \tTest accuracy 0.9812\n",
      "Epoch 206 \tTrain accuracy 0.8125 \tTest accuracy 0.9814\n",
      "Epoch 207 \tTrain accuracy 0.8375 \tTest accuracy 0.9774\n",
      "Epoch 208 \tTrain accuracy 0.8875 \tTest accuracy 0.9799\n",
      "Epoch 209 \tTrain accuracy 0.9000 \tTest accuracy 0.9819\n",
      "Epoch 210 \tTrain accuracy 0.8625 \tTest accuracy 0.9793\n",
      "Epoch 211 \tTrain accuracy 0.8750 \tTest accuracy 0.9790\n",
      "Epoch 212 \tTrain accuracy 0.7875 \tTest accuracy 0.9794\n",
      "Epoch 213 \tTrain accuracy 0.7375 \tTest accuracy 0.9780\n",
      "Epoch 214 \tTrain accuracy 0.8000 \tTest accuracy 0.9793\n",
      "Epoch 215 \tTrain accuracy 0.8500 \tTest accuracy 0.9786\n",
      "Epoch 216 \tTrain accuracy 0.7375 \tTest accuracy 0.9782\n",
      "Epoch 217 \tTrain accuracy 0.8625 \tTest accuracy 0.9800\n",
      "Epoch 218 \tTrain accuracy 0.8375 \tTest accuracy 0.9809\n",
      "Epoch 219 \tTrain accuracy 0.8500 \tTest accuracy 0.9788\n",
      "Epoch 220 \tTrain accuracy 0.8375 \tTest accuracy 0.9801\n",
      "Epoch 221 \tTrain accuracy 0.8125 \tTest accuracy 0.9787\n",
      "Epoch 222 \tTrain accuracy 0.8125 \tTest accuracy 0.9771\n",
      "Epoch 223 \tTrain accuracy 0.8125 \tTest accuracy 0.9781\n",
      "Epoch 224 \tTrain accuracy 0.8375 \tTest accuracy 0.9787\n",
      "Epoch 225 \tTrain accuracy 0.7500 \tTest accuracy 0.9803\n",
      "Epoch 226 \tTrain accuracy 0.8500 \tTest accuracy 0.9813\n",
      "Epoch 227 \tTrain accuracy 0.8625 \tTest accuracy 0.9800\n",
      "Epoch 228 \tTrain accuracy 0.7750 \tTest accuracy 0.9797\n",
      "Epoch 229 \tTrain accuracy 0.7875 \tTest accuracy 0.9802\n",
      "Epoch 230 \tTrain accuracy 0.7625 \tTest accuracy 0.9807\n",
      "Epoch 231 \tTrain accuracy 0.8500 \tTest accuracy 0.9808\n",
      "Epoch 232 \tTrain accuracy 0.7250 \tTest accuracy 0.9813\n",
      "Epoch 233 \tTrain accuracy 0.7375 \tTest accuracy 0.9793\n",
      "Epoch 234 \tTrain accuracy 0.9500 \tTest accuracy 0.9785\n",
      "Epoch 235 \tTrain accuracy 0.8875 \tTest accuracy 0.9808\n",
      "Epoch 236 \tTrain accuracy 0.7250 \tTest accuracy 0.9811\n",
      "Epoch 237 \tTrain accuracy 0.8375 \tTest accuracy 0.9776\n",
      "Epoch 238 \tTrain accuracy 0.7625 \tTest accuracy 0.9781\n",
      "Epoch 239 \tTrain accuracy 0.7750 \tTest accuracy 0.9823\n",
      "Epoch 240 \tTrain accuracy 0.7750 \tTest accuracy 0.9770\n",
      "Epoch 241 \tTrain accuracy 0.8625 \tTest accuracy 0.9783\n",
      "Epoch 242 \tTrain accuracy 0.7875 \tTest accuracy 0.9794\n",
      "Epoch 243 \tTrain accuracy 0.8375 \tTest accuracy 0.9794\n",
      "Epoch 244 \tTrain accuracy 0.8375 \tTest accuracy 0.9760\n",
      "Epoch 245 \tTrain accuracy 0.8000 \tTest accuracy 0.9788\n",
      "Epoch 246 \tTrain accuracy 0.7625 \tTest accuracy 0.9813\n",
      "Epoch 247 \tTrain accuracy 0.7750 \tTest accuracy 0.9774\n",
      "Epoch 248 \tTrain accuracy 0.8375 \tTest accuracy 0.9806\n",
      "Epoch 249 \tTrain accuracy 0.7750 \tTest accuracy 0.9791\n",
      "Epoch 250 \tTrain accuracy 0.7750 \tTest accuracy 0.9796\n",
      "Epoch 251 \tTrain accuracy 0.8125 \tTest accuracy 0.9797\n",
      "Epoch 252 \tTrain accuracy 0.7750 \tTest accuracy 0.9793\n",
      "Epoch 253 \tTrain accuracy 0.8750 \tTest accuracy 0.9804\n",
      "Epoch 254 \tTrain accuracy 0.8125 \tTest accuracy 0.9813\n",
      "Epoch 255 \tTrain accuracy 0.7750 \tTest accuracy 0.9760\n",
      "Epoch 256 \tTrain accuracy 0.7750 \tTest accuracy 0.9791\n",
      "Epoch 257 \tTrain accuracy 0.8500 \tTest accuracy 0.9795\n",
      "Epoch 258 \tTrain accuracy 0.8375 \tTest accuracy 0.9815\n",
      "Epoch 259 \tTrain accuracy 0.8500 \tTest accuracy 0.9797\n",
      "Epoch 260 \tTrain accuracy 0.7375 \tTest accuracy 0.9803\n",
      "Epoch 261 \tTrain accuracy 0.7875 \tTest accuracy 0.9810\n",
      "Epoch 262 \tTrain accuracy 0.8250 \tTest accuracy 0.9812\n",
      "Epoch 263 \tTrain accuracy 0.8250 \tTest accuracy 0.9808\n",
      "Epoch 264 \tTrain accuracy 0.8250 \tTest accuracy 0.9807\n",
      "Epoch 265 \tTrain accuracy 0.8000 \tTest accuracy 0.9795\n",
      "Epoch 266 \tTrain accuracy 0.8000 \tTest accuracy 0.9808\n",
      "Epoch 267 \tTrain accuracy 0.8750 \tTest accuracy 0.9779\n",
      "Epoch 268 \tTrain accuracy 0.8250 \tTest accuracy 0.9797\n",
      "Epoch 269 \tTrain accuracy 0.8125 \tTest accuracy 0.9799\n",
      "Epoch 270 \tTrain accuracy 0.8125 \tTest accuracy 0.9805\n",
      "Epoch 271 \tTrain accuracy 0.8000 \tTest accuracy 0.9789\n",
      "Epoch 272 \tTrain accuracy 0.8500 \tTest accuracy 0.9803\n",
      "Epoch 273 \tTrain accuracy 0.8125 \tTest accuracy 0.9816\n",
      "Epoch 274 \tTrain accuracy 0.6875 \tTest accuracy 0.9786\n",
      "Epoch 275 \tTrain accuracy 0.8250 \tTest accuracy 0.9812\n",
      "Epoch 276 \tTrain accuracy 0.8250 \tTest accuracy 0.9793\n",
      "Epoch 277 \tTrain accuracy 0.7375 \tTest accuracy 0.9805\n",
      "Epoch 278 \tTrain accuracy 0.8625 \tTest accuracy 0.9787\n",
      "Epoch 279 \tTrain accuracy 0.8000 \tTest accuracy 0.9811\n",
      "Epoch 280 \tTrain accuracy 0.8000 \tTest accuracy 0.9788\n",
      "Epoch 281 \tTrain accuracy 0.7375 \tTest accuracy 0.9802\n",
      "Epoch 282 \tTrain accuracy 0.8500 \tTest accuracy 0.9807\n",
      "Epoch 283 \tTrain accuracy 0.8375 \tTest accuracy 0.9809\n",
      "Epoch 284 \tTrain accuracy 0.7375 \tTest accuracy 0.9820\n",
      "Epoch 285 \tTrain accuracy 0.8000 \tTest accuracy 0.9809\n",
      "Epoch 286 \tTrain accuracy 0.8375 \tTest accuracy 0.9800\n",
      "Epoch 287 \tTrain accuracy 0.8500 \tTest accuracy 0.9810\n",
      "Epoch 288 \tTrain accuracy 0.8500 \tTest accuracy 0.9795\n",
      "Epoch 289 \tTrain accuracy 0.8250 \tTest accuracy 0.9810\n",
      "Epoch 290 \tTrain accuracy 0.8375 \tTest accuracy 0.9810\n",
      "Epoch 291 \tTrain accuracy 0.8625 \tTest accuracy 0.9812\n",
      "Epoch 292 \tTrain accuracy 0.7875 \tTest accuracy 0.9805\n",
      "Epoch 293 \tTrain accuracy 0.7000 \tTest accuracy 0.9798\n",
      "Epoch 294 \tTrain accuracy 0.7125 \tTest accuracy 0.9787\n",
      "Epoch 295 \tTrain accuracy 0.8125 \tTest accuracy 0.9802\n",
      "Epoch 296 \tTrain accuracy 0.7625 \tTest accuracy 0.9792\n",
      "Epoch 297 \tTrain accuracy 0.7625 \tTest accuracy 0.9820\n",
      "Epoch 298 \tTrain accuracy 0.7875 \tTest accuracy 0.9807\n",
      "Epoch 299 \tTrain accuracy 0.7250 \tTest accuracy 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300 \tTrain accuracy 0.8000 \tTest accuracy 0.9800\n",
      "Epoch 301 \tTrain accuracy 0.7375 \tTest accuracy 0.9797\n",
      "Epoch 302 \tTrain accuracy 0.7625 \tTest accuracy 0.9805\n",
      "Epoch 303 \tTrain accuracy 0.8125 \tTest accuracy 0.9810\n",
      "Epoch 304 \tTrain accuracy 0.6375 \tTest accuracy 0.9782\n",
      "Epoch 305 \tTrain accuracy 0.7750 \tTest accuracy 0.9820\n",
      "Epoch 306 \tTrain accuracy 0.8875 \tTest accuracy 0.9824\n",
      "Epoch 307 \tTrain accuracy 0.7875 \tTest accuracy 0.9789\n",
      "Epoch 308 \tTrain accuracy 0.8625 \tTest accuracy 0.9807\n",
      "Epoch 309 \tTrain accuracy 0.8000 \tTest accuracy 0.9814\n",
      "Epoch 310 \tTrain accuracy 0.7000 \tTest accuracy 0.9806\n",
      "Epoch 311 \tTrain accuracy 0.7000 \tTest accuracy 0.9791\n",
      "Epoch 312 \tTrain accuracy 0.7500 \tTest accuracy 0.9796\n",
      "Epoch 313 \tTrain accuracy 0.8625 \tTest accuracy 0.9801\n",
      "Epoch 314 \tTrain accuracy 0.8125 \tTest accuracy 0.9804\n",
      "Epoch 315 \tTrain accuracy 0.7250 \tTest accuracy 0.9812\n",
      "Epoch 316 \tTrain accuracy 0.8375 \tTest accuracy 0.9818\n",
      "Epoch 317 \tTrain accuracy 0.8000 \tTest accuracy 0.9825\n",
      "Epoch 318 \tTrain accuracy 0.8125 \tTest accuracy 0.9828\n",
      "Epoch 319 \tTrain accuracy 0.8125 \tTest accuracy 0.9830\n",
      "Epoch 320 \tTrain accuracy 0.8250 \tTest accuracy 0.9829\n",
      "Epoch 321 \tTrain accuracy 0.8000 \tTest accuracy 0.9830\n",
      "Epoch 322 \tTrain accuracy 0.7375 \tTest accuracy 0.9830\n",
      "Epoch 323 \tTrain accuracy 0.7875 \tTest accuracy 0.9830\n",
      "Epoch 324 \tTrain accuracy 0.7500 \tTest accuracy 0.9830\n",
      "Epoch 325 \tTrain accuracy 0.8250 \tTest accuracy 0.9831\n",
      "Epoch 326 \tTrain accuracy 0.8000 \tTest accuracy 0.9830\n",
      "Epoch 327 \tTrain accuracy 0.7750 \tTest accuracy 0.9830\n",
      "Epoch 328 \tTrain accuracy 0.7125 \tTest accuracy 0.9831\n",
      "Epoch 329 \tTrain accuracy 0.7750 \tTest accuracy 0.9829\n",
      "Epoch 330 \tTrain accuracy 0.7875 \tTest accuracy 0.9830\n",
      "Epoch 331 \tTrain accuracy 0.7750 \tTest accuracy 0.9830\n",
      "Epoch 332 \tTrain accuracy 0.8500 \tTest accuracy 0.9830\n",
      "Epoch 333 \tTrain accuracy 0.8000 \tTest accuracy 0.9829\n",
      "Epoch 334 \tTrain accuracy 0.7500 \tTest accuracy 0.9830\n",
      "Epoch 335 \tTrain accuracy 0.7500 \tTest accuracy 0.9831\n",
      "Epoch 336 \tTrain accuracy 0.7750 \tTest accuracy 0.9830\n",
      "Epoch 337 \tTrain accuracy 0.7375 \tTest accuracy 0.9830\n",
      "Epoch 338 \tTrain accuracy 0.7750 \tTest accuracy 0.9829\n",
      "Epoch 339 \tTrain accuracy 0.7875 \tTest accuracy 0.9829\n",
      "Epoch 340 \tTrain accuracy 0.8125 \tTest accuracy 0.9829\n",
      "Epoch 341 \tTrain accuracy 0.7875 \tTest accuracy 0.9828\n",
      "Epoch 342 \tTrain accuracy 0.7000 \tTest accuracy 0.9827\n",
      "Epoch 343 \tTrain accuracy 0.8250 \tTest accuracy 0.9828\n",
      "Epoch 344 \tTrain accuracy 0.8000 \tTest accuracy 0.9829\n",
      "Epoch 345 \tTrain accuracy 0.8500 \tTest accuracy 0.9829\n",
      "Epoch 346 \tTrain accuracy 0.8750 \tTest accuracy 0.9829\n",
      "Epoch 347 \tTrain accuracy 0.7625 \tTest accuracy 0.9828\n",
      "Epoch 348 \tTrain accuracy 0.8750 \tTest accuracy 0.9828\n",
      "Epoch 349 \tTrain accuracy 0.8250 \tTest accuracy 0.9828\n",
      "Epoch 350 \tTrain accuracy 0.7875 \tTest accuracy 0.9829\n",
      "Epoch 351 \tTrain accuracy 0.7875 \tTest accuracy 0.9829\n",
      "Epoch 352 \tTrain accuracy 0.8125 \tTest accuracy 0.9829\n",
      "Epoch 353 \tTrain accuracy 0.8125 \tTest accuracy 0.9829\n",
      "Epoch 354 \tTrain accuracy 0.7875 \tTest accuracy 0.9829\n",
      "Epoch 355 \tTrain accuracy 0.7125 \tTest accuracy 0.9830\n",
      "Epoch 356 \tTrain accuracy 0.7375 \tTest accuracy 0.9830\n",
      "Epoch 357 \tTrain accuracy 0.7750 \tTest accuracy 0.9830\n",
      "Epoch 358 \tTrain accuracy 0.8750 \tTest accuracy 0.9832\n",
      "Epoch 359 \tTrain accuracy 0.8125 \tTest accuracy 0.9833\n",
      "Epoch 360 \tTrain accuracy 0.7750 \tTest accuracy 0.9833\n",
      "Epoch 361 \tTrain accuracy 0.8375 \tTest accuracy 0.9833\n",
      "Epoch 362 \tTrain accuracy 0.8125 \tTest accuracy 0.9833\n",
      "Epoch 363 \tTrain accuracy 0.8250 \tTest accuracy 0.9833\n",
      "Epoch 364 \tTrain accuracy 0.8375 \tTest accuracy 0.9833\n",
      "Epoch 365 \tTrain accuracy 0.8125 \tTest accuracy 0.9833\n",
      "Epoch 366 \tTrain accuracy 0.8375 \tTest accuracy 0.9830\n",
      "Epoch 367 \tTrain accuracy 0.8250 \tTest accuracy 0.9831\n",
      "Epoch 368 \tTrain accuracy 0.8500 \tTest accuracy 0.9832\n",
      "Epoch 369 \tTrain accuracy 0.7750 \tTest accuracy 0.9832\n",
      "Epoch 370 \tTrain accuracy 0.7625 \tTest accuracy 0.9833\n",
      "Epoch 371 \tTrain accuracy 0.8750 \tTest accuracy 0.9833\n",
      "Epoch 372 \tTrain accuracy 0.7875 \tTest accuracy 0.9833\n",
      "Epoch 373 \tTrain accuracy 0.8750 \tTest accuracy 0.9833\n",
      "Epoch 374 \tTrain accuracy 0.8000 \tTest accuracy 0.9833\n",
      "Epoch 375 \tTrain accuracy 0.8500 \tTest accuracy 0.9833\n",
      "Epoch 376 \tTrain accuracy 0.8375 \tTest accuracy 0.9833\n",
      "Epoch 377 \tTrain accuracy 0.8375 \tTest accuracy 0.9833\n",
      "Epoch 378 \tTrain accuracy 0.8375 \tTest accuracy 0.9833\n",
      "Epoch 379 \tTrain accuracy 0.8500 \tTest accuracy 0.9833\n",
      "Epoch 380 \tTrain accuracy 0.7750 \tTest accuracy 0.9833\n",
      "Epoch 381 \tTrain accuracy 0.7875 \tTest accuracy 0.9833\n",
      "Epoch 382 \tTrain accuracy 0.8625 \tTest accuracy 0.9833\n",
      "Epoch 383 \tTrain accuracy 0.7625 \tTest accuracy 0.9832\n",
      "Epoch 384 \tTrain accuracy 0.8000 \tTest accuracy 0.9833\n",
      "Epoch 385 \tTrain accuracy 0.7250 \tTest accuracy 0.9833\n",
      "Epoch 386 \tTrain accuracy 0.8375 \tTest accuracy 0.9833\n",
      "Epoch 387 \tTrain accuracy 0.7875 \tTest accuracy 0.9833\n",
      "Epoch 388 \tTrain accuracy 0.7875 \tTest accuracy 0.9833\n",
      "Epoch 389 \tTrain accuracy 0.8250 \tTest accuracy 0.9833\n",
      "Epoch 390 \tTrain accuracy 0.8500 \tTest accuracy 0.9833\n",
      "Epoch 391 \tTrain accuracy 0.8250 \tTest accuracy 0.9833\n",
      "Epoch 392 \tTrain accuracy 0.8125 \tTest accuracy 0.9833\n",
      "Epoch 393 \tTrain accuracy 0.7500 \tTest accuracy 0.9833\n",
      "Epoch 394 \tTrain accuracy 0.8625 \tTest accuracy 0.9834\n",
      "Epoch 395 \tTrain accuracy 0.7625 \tTest accuracy 0.9833\n",
      "Epoch 396 \tTrain accuracy 0.8125 \tTest accuracy 0.9833\n",
      "Epoch 397 \tTrain accuracy 0.7875 \tTest accuracy 0.9832\n",
      "Epoch 398 \tTrain accuracy 0.8750 \tTest accuracy 0.9830\n",
      "Epoch 399 \tTrain accuracy 0.8000 \tTest accuracy 0.9830\n",
      "Epoch 400 \tTrain accuracy 0.8500 \tTest accuracy 0.9830\n",
      "Epoch 401 \tTrain accuracy 0.7750 \tTest accuracy 0.9781\n",
      "Epoch 402 \tTrain accuracy 0.7625 \tTest accuracy 0.9812\n",
      "Epoch 403 \tTrain accuracy 0.7250 \tTest accuracy 0.9816\n",
      "Epoch 404 \tTrain accuracy 0.7625 \tTest accuracy 0.9812\n",
      "Epoch 405 \tTrain accuracy 0.6875 \tTest accuracy 0.9821\n",
      "Epoch 406 \tTrain accuracy 0.8375 \tTest accuracy 0.9812\n",
      "Epoch 407 \tTrain accuracy 0.8125 \tTest accuracy 0.9805\n",
      "Epoch 408 \tTrain accuracy 0.8000 \tTest accuracy 0.9812\n",
      "Epoch 409 \tTrain accuracy 0.8875 \tTest accuracy 0.9816\n",
      "Epoch 410 \tTrain accuracy 0.7875 \tTest accuracy 0.9792\n",
      "Epoch 411 \tTrain accuracy 0.7500 \tTest accuracy 0.9797\n",
      "Epoch 412 \tTrain accuracy 0.8250 \tTest accuracy 0.9799\n",
      "Epoch 413 \tTrain accuracy 0.8250 \tTest accuracy 0.9814\n",
      "Epoch 414 \tTrain accuracy 0.8250 \tTest accuracy 0.9807\n",
      "Epoch 415 \tTrain accuracy 0.7875 \tTest accuracy 0.9800\n",
      "Epoch 416 \tTrain accuracy 0.8000 \tTest accuracy 0.9796\n",
      "Epoch 417 \tTrain accuracy 0.9125 \tTest accuracy 0.9817\n",
      "Epoch 418 \tTrain accuracy 0.7500 \tTest accuracy 0.9818\n",
      "Epoch 419 \tTrain accuracy 0.7875 \tTest accuracy 0.9803\n",
      "Epoch 420 \tTrain accuracy 0.6375 \tTest accuracy 0.9794\n",
      "Epoch 421 \tTrain accuracy 0.7375 \tTest accuracy 0.9772\n",
      "Epoch 422 \tTrain accuracy 0.7875 \tTest accuracy 0.9805\n",
      "Epoch 423 \tTrain accuracy 0.6875 \tTest accuracy 0.9791\n",
      "Epoch 424 \tTrain accuracy 0.8000 \tTest accuracy 0.9806\n",
      "Epoch 425 \tTrain accuracy 0.8250 \tTest accuracy 0.9780\n",
      "Epoch 426 \tTrain accuracy 0.7875 \tTest accuracy 0.9795\n",
      "Epoch 427 \tTrain accuracy 0.7875 \tTest accuracy 0.9788\n",
      "Epoch 428 \tTrain accuracy 0.8000 \tTest accuracy 0.9762\n",
      "Epoch 429 \tTrain accuracy 0.7500 \tTest accuracy 0.9776\n",
      "Epoch 430 \tTrain accuracy 0.7000 \tTest accuracy 0.9805\n",
      "Epoch 431 \tTrain accuracy 0.8000 \tTest accuracy 0.9811\n",
      "Epoch 432 \tTrain accuracy 0.7375 \tTest accuracy 0.9807\n",
      "Epoch 433 \tTrain accuracy 0.7875 \tTest accuracy 0.9813\n",
      "Epoch 434 \tTrain accuracy 0.7500 \tTest accuracy 0.9807\n",
      "Epoch 435 \tTrain accuracy 0.8500 \tTest accuracy 0.9807\n",
      "Epoch 436 \tTrain accuracy 0.7875 \tTest accuracy 0.9827\n",
      "Epoch 437 \tTrain accuracy 0.8250 \tTest accuracy 0.9821\n",
      "Epoch 438 \tTrain accuracy 0.7875 \tTest accuracy 0.9792\n",
      "Epoch 439 \tTrain accuracy 0.8375 \tTest accuracy 0.9784\n",
      "Epoch 440 \tTrain accuracy 0.8250 \tTest accuracy 0.9807\n",
      "Epoch 441 \tTrain accuracy 0.7250 \tTest accuracy 0.9804\n",
      "Epoch 442 \tTrain accuracy 0.7500 \tTest accuracy 0.9810\n",
      "Epoch 443 \tTrain accuracy 0.7250 \tTest accuracy 0.9805\n",
      "Epoch 444 \tTrain accuracy 0.8125 \tTest accuracy 0.9813\n",
      "Epoch 445 \tTrain accuracy 0.8375 \tTest accuracy 0.9810\n",
      "Epoch 446 \tTrain accuracy 0.8000 \tTest accuracy 0.9813\n",
      "Epoch 447 \tTrain accuracy 0.7375 \tTest accuracy 0.9819\n",
      "Epoch 448 \tTrain accuracy 0.7875 \tTest accuracy 0.9804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449 \tTrain accuracy 0.7625 \tTest accuracy 0.9799\n",
      "Epoch 450 \tTrain accuracy 0.6750 \tTest accuracy 0.9797\n",
      "Epoch 451 \tTrain accuracy 0.8125 \tTest accuracy 0.9795\n",
      "Epoch 452 \tTrain accuracy 0.7875 \tTest accuracy 0.9800\n",
      "Epoch 453 \tTrain accuracy 0.7875 \tTest accuracy 0.9782\n",
      "Epoch 454 \tTrain accuracy 0.8375 \tTest accuracy 0.9779\n",
      "Epoch 455 \tTrain accuracy 0.8125 \tTest accuracy 0.9795\n",
      "Epoch 456 \tTrain accuracy 0.7250 \tTest accuracy 0.9784\n",
      "Epoch 457 \tTrain accuracy 0.7750 \tTest accuracy 0.9803\n",
      "Epoch 458 \tTrain accuracy 0.7625 \tTest accuracy 0.9794\n",
      "Epoch 459 \tTrain accuracy 0.7125 \tTest accuracy 0.9793\n",
      "Epoch 460 \tTrain accuracy 0.8000 \tTest accuracy 0.9789\n",
      "Epoch 461 \tTrain accuracy 0.7250 \tTest accuracy 0.9824\n",
      "Epoch 462 \tTrain accuracy 0.8125 \tTest accuracy 0.9825\n",
      "Epoch 463 \tTrain accuracy 0.7500 \tTest accuracy 0.9804\n",
      "Epoch 464 \tTrain accuracy 0.8625 \tTest accuracy 0.9794\n",
      "Epoch 465 \tTrain accuracy 0.8000 \tTest accuracy 0.9793\n",
      "Epoch 466 \tTrain accuracy 0.7250 \tTest accuracy 0.9821\n",
      "Epoch 467 \tTrain accuracy 0.8250 \tTest accuracy 0.9808\n",
      "Epoch 468 \tTrain accuracy 0.7125 \tTest accuracy 0.9782\n",
      "Epoch 469 \tTrain accuracy 0.8375 \tTest accuracy 0.9803\n",
      "Epoch 470 \tTrain accuracy 0.7250 \tTest accuracy 0.9809\n",
      "Epoch 471 \tTrain accuracy 0.6125 \tTest accuracy 0.9801\n",
      "Epoch 472 \tTrain accuracy 0.7375 \tTest accuracy 0.9815\n",
      "Epoch 473 \tTrain accuracy 0.7375 \tTest accuracy 0.9817\n",
      "Epoch 474 \tTrain accuracy 0.8625 \tTest accuracy 0.9820\n",
      "Epoch 475 \tTrain accuracy 0.7875 \tTest accuracy 0.9804\n",
      "Epoch 476 \tTrain accuracy 0.8625 \tTest accuracy 0.9807\n",
      "Epoch 477 \tTrain accuracy 0.6625 \tTest accuracy 0.9807\n",
      "Epoch 478 \tTrain accuracy 0.7375 \tTest accuracy 0.9793\n",
      "Epoch 479 \tTrain accuracy 0.8125 \tTest accuracy 0.9811\n",
      "Epoch 480 \tTrain accuracy 0.7500 \tTest accuracy 0.9813\n",
      "Epoch 481 \tTrain accuracy 0.8625 \tTest accuracy 0.9788\n",
      "Epoch 482 \tTrain accuracy 0.7625 \tTest accuracy 0.9800\n",
      "Epoch 483 \tTrain accuracy 0.7750 \tTest accuracy 0.9787\n",
      "Epoch 484 \tTrain accuracy 0.8000 \tTest accuracy 0.9806\n",
      "Epoch 485 \tTrain accuracy 0.7125 \tTest accuracy 0.9805\n",
      "Epoch 486 \tTrain accuracy 0.8250 \tTest accuracy 0.9811\n",
      "Epoch 487 \tTrain accuracy 0.7500 \tTest accuracy 0.9804\n",
      "Epoch 488 \tTrain accuracy 0.8000 \tTest accuracy 0.9815\n",
      "Epoch 489 \tTrain accuracy 0.8625 \tTest accuracy 0.9791\n",
      "Epoch 490 \tTrain accuracy 0.6750 \tTest accuracy 0.9802\n",
      "Epoch 491 \tTrain accuracy 0.7125 \tTest accuracy 0.9802\n",
      "Epoch 492 \tTrain accuracy 0.7250 \tTest accuracy 0.9806\n",
      "Epoch 493 \tTrain accuracy 0.7250 \tTest accuracy 0.9783\n",
      "Epoch 494 \tTrain accuracy 0.7500 \tTest accuracy 0.9787\n",
      "Epoch 495 \tTrain accuracy 0.8000 \tTest accuracy 0.9800\n",
      "Epoch 496 \tTrain accuracy 0.7625 \tTest accuracy 0.9800\n",
      "Epoch 497 \tTrain accuracy 0.8375 \tTest accuracy 0.9811\n",
      "Epoch 498 \tTrain accuracy 0.7375 \tTest accuracy 0.9815\n",
      "Epoch 499 \tTrain accuracy 0.7000 \tTest accuracy 0.9823\n",
      "\n",
      "Final Accuracy 0.9834001064300537\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for step in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_op, feed_dict={X: X_batch, y: y_batch, learning_rate: 0.001})\n",
    "        acc_train = accuracy.eval(feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Epoch {:>2d}\".format(epoch), \"\\tTrain accuracy {:.4f}\".format(acc_train), \n",
    "                                                  \"\\tTest accuracy {:.4f}\".format(acc_test))\n",
    "        if acc_test > final_accuracy:\n",
    "            final_accuracy = acc_test\n",
    "    save_model = saver.save(sess, \"models/my_model_final.ckpt\")\n",
    "    print(\"\\nFinal Accuracy {}\".format(final_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Not much of an improvment, because we have a shallow network. But, this is faster and more efficient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
