{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST via TF's low-level Python API, 3 hidden layers (Deep Neural Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #Resets the graph that was already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28*28 # = 784\n",
    "n_hidden1 = 320\n",
    "n_hidden2 = 120\n",
    "n_hidden3 = 50\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Placeholders for images\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\") \n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef layer(X, n_neurons, name, activation=None):\\n    with tf.name_scope(name):\\n        n_inputs = int(X.get_shape()[1])\\n        stddev = 2 / np.sqrt(n_inputs)\\n        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\\n        W = tf.Variable(init, name=\"kernel\")\\n        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\\n        lout = tf.matmul(X, W) + b\\n        if activation is not None:\\n            return activation(lout)\\n        else:\\n            return lout\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function representing a layer\n",
    "#Tensorflow achieves this with one line, so this is commented out\n",
    "'''\n",
    "def layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        lout = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(lout)\n",
    "        else:\n",
    "            return lout\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\\nhidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\\nhidden3 = neuron_layer(hidden2, n_hidden3, name=\"hidden3\", activation=tf.nn.relu)   \\nlogits = neuron_layer(hidden3, n_outputs, name=\"outputs\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "hidden3 = neuron_layer(hidden2, n_hidden3, name=\"hidden3\", activation=tf.nn.relu)   \n",
    "logits = neuron_layer(hidden3, n_outputs, name=\"outputs\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating layers of a neural network\n",
    "with tf.name_scope(\"layers\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu) #\"dense\" means \"fully connected\"\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, name=\"hidden3\", activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden3, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\") #Reduce mean of cross entropy for the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1 #Large enough to jump from one local minimum to another\n",
    "\n",
    "with tf.name_scope(\"minimize\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() #Saves checkpoints since this takes a while to train, saves the whole graph of all the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 20 #Number of passes through the data\n",
    "batch_size = 50\n",
    "#A total of 240,000 passes through a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 \tTrain accuracy 1.0000 \tTest accuracy 0.9555\n",
      "Epoch  1 \tTrain accuracy 1.0000 \tTest accuracy 0.9701\n",
      "Epoch  2 \tTrain accuracy 1.0000 \tTest accuracy 0.9726\n",
      "Epoch  3 \tTrain accuracy 1.0000 \tTest accuracy 0.9694\n",
      "Epoch  4 \tTrain accuracy 1.0000 \tTest accuracy 0.9760\n",
      "Epoch  5 \tTrain accuracy 1.0000 \tTest accuracy 0.9798\n",
      "Epoch  6 \tTrain accuracy 1.0000 \tTest accuracy 0.9797\n",
      "Epoch  7 \tTrain accuracy 1.0000 \tTest accuracy 0.9800\n",
      "Epoch  8 \tTrain accuracy 1.0000 \tTest accuracy 0.9804\n",
      "Epoch  9 \tTrain accuracy 1.0000 \tTest accuracy 0.9808\n",
      "Epoch 10 \tTrain accuracy 1.0000 \tTest accuracy 0.9817\n",
      "Epoch 11 \tTrain accuracy 1.0000 \tTest accuracy 0.9824\n",
      "Epoch 12 \tTrain accuracy 1.0000 \tTest accuracy 0.9824\n",
      "Epoch 13 \tTrain accuracy 1.0000 \tTest accuracy 0.9833\n",
      "Epoch 14 \tTrain accuracy 1.0000 \tTest accuracy 0.9830\n",
      "Epoch 15 \tTrain accuracy 1.0000 \tTest accuracy 0.9830\n",
      "Epoch 16 \tTrain accuracy 1.0000 \tTest accuracy 0.9829\n",
      "Epoch 17 \tTrain accuracy 1.0000 \tTest accuracy 0.9827\n",
      "Epoch 18 \tTrain accuracy 1.0000 \tTest accuracy 0.9831\n",
      "Epoch 19 \tTrain accuracy 1.0000 \tTest accuracy 0.9828\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for step in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Epoch {:>2d}\".format(epoch), \"\\tTrain accuracy {:.4f}\".format(acc_train), \n",
    "                                                  \"\\tTest accuracy {:.4f}\".format(acc_test))\n",
    "    final_accuracy = acc_test\n",
    "    save_model = saver.save(sess, \"models/my_model_first.ckpt\") #Saves the final model in a directory called \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a while, with a large learning rate, we can't do better than this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001 #New lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/my_model_first.ckpt\n",
      "Epoch  0 \tTrain accuracy 1.0000 \tTest accuracy 0.9832\n",
      "Epoch  1 \tTrain accuracy 1.0000 \tTest accuracy 0.9828\n",
      "Epoch  2 \tTrain accuracy 1.0000 \tTest accuracy 0.9826\n",
      "Epoch  3 \tTrain accuracy 1.0000 \tTest accuracy 0.9827\n",
      "Epoch  4 \tTrain accuracy 1.0000 \tTest accuracy 0.9827\n",
      "Epoch  5 \tTrain accuracy 1.0000 \tTest accuracy 0.9828\n",
      "Epoch  6 \tTrain accuracy 1.0000 \tTest accuracy 0.9829\n",
      "Epoch  7 \tTrain accuracy 1.0000 \tTest accuracy 0.9829\n",
      "Epoch  8 \tTrain accuracy 1.0000 \tTest accuracy 0.9831\n",
      "Epoch  9 \tTrain accuracy 1.0000 \tTest accuracy 0.9830\n",
      "Epoch 10 \tTrain accuracy 1.0000 \tTest accuracy 0.9830\n",
      "Epoch 11 \tTrain accuracy 1.0000 \tTest accuracy 0.9829\n",
      "Epoch 12 \tTrain accuracy 1.0000 \tTest accuracy 0.9830\n",
      "Epoch 13 \tTrain accuracy 1.0000 \tTest accuracy 0.9830\n",
      "Epoch 14 \tTrain accuracy 1.0000 \tTest accuracy 0.9829\n",
      "Epoch 15 \tTrain accuracy 1.0000 \tTest accuracy 0.9831\n",
      "Epoch 16 \tTrain accuracy 1.0000 \tTest accuracy 0.9828\n",
      "Epoch 17 \tTrain accuracy 1.0000 \tTest accuracy 0.9831\n",
      "Epoch 18 \tTrain accuracy 1.0000 \tTest accuracy 0.9829\n",
      "Epoch 19 \tTrain accuracy 1.0000 \tTest accuracy 0.9831\n",
      "\n",
      "Final Accuracy 0.9832000136375427\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"models/my_model_first.ckpt\")\n",
    "    for epoch in range(n_epochs):\n",
    "        for step in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Epoch {:>2d}\".format(epoch), \"\\tTrain accuracy {:.4f}\".format(acc_train), \n",
    "                                                  \"\\tTest accuracy {:.4f}\".format(acc_test))\n",
    "        if acc_test > final_accuracy:\n",
    "            final_accuracy = acc_test\n",
    "            save_model = saver.save(sess, \"models/my_model_final.ckpt\") #Save the model with the highest accuracy\n",
    "    print(\"\\nFinal Accuracy {}\".format(final_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
